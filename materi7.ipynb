{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week #4 - Data Transformation\n",
    "Data Pipeline Course - Sekolah Engineer - Pacmann Academy \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description \n",
    "Data transformation involves modifying or converting data from one format, structure, or representation to another, typically to make it more suitable for downstream processing, analysis, or storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Description\n",
    "<img src='pict/transformation1.png' width=\"800\"> <br>\n",
    "\n",
    "In the Data Extraction and Load module, we successfully extracted and load data to staging area\n",
    "\n",
    "In the Data Transformation module, we will focus on the following tasks:\n",
    "1. Transform the data from the staging area to align with the given Target Data Model schema.\n",
    "2. Validate the transformed data. If the data does not meet the validation criteria, it will not be loaded into the database.\n",
    "3. Load the validated and transformed data into the target system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Data Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pict/transformation2.png' width=\"800\"> <br>\n",
    "\n",
    "\n",
    "Create your database with this DDL:\n",
    "``` sql\n",
    "-- Create the category table\n",
    "CREATE TABLE category (\n",
    "    category_id SERIAL PRIMARY KEY,\n",
    "    category_nk int unique,\n",
    "    name VARCHAR(255) NOT NULL,\n",
    "    description TEXT,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\n",
    "\n",
    "-- Create the customer table\n",
    "CREATE TABLE customer (\n",
    "    customer_id SERIAL PRIMARY KEY,\n",
    "    customer_nk int unique, \n",
    "    first_name VARCHAR(255) NOT NULL,\n",
    "    last_name VARCHAR(255) NOT NULL,\n",
    "    email VARCHAR(255) NOT NULL,\n",
    "    phone VARCHAR(100),\n",
    "    address TEXT,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\n",
    "-- Create the order table\n",
    "CREATE TABLE orders (\n",
    "    order_id SERIAL PRIMARY KEY,\n",
    "    order_nk varchar(255) unique,\n",
    "    customer_id INT REFERENCES customer(customer_id),\n",
    "    order_date DATE NOT NULL,\n",
    "    status varchar NOT NULL,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\n",
    "CREATE TABLE order_detail (\n",
    "    order_detail_id SERIAL PRIMARY KEY,\n",
    "    order_id int REFERENCES orders(order_id),\n",
    "    product_id varchar(255) NOT NULL,\n",
    "    price NUMERIC(10, 2) NOT NULL,\n",
    "    quantity INT NOT NULL,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    UNIQUE(order_id, product_id, quantity)\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source to Target Maping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conducting Data Profiling on the source, here is the source-to-target mapping information that we will use for the transformation process.\n",
    "\n",
    "### Table Category\n",
    "source: category table\n",
    "\n",
    "| Source Field | Target Field  | Transformation Rule           |\n",
    "|--------------|---------------|--------------------------------|\n",
    "| -            | category_id   | Auto Generated                 |\n",
    "| category_id  | category_nk   | Direct mapping, unique         |\n",
    "| name         | name          | Direct mapping, unique         |\n",
    "| description  | description   | Direct mapping                 |\n",
    "\n",
    "\n",
    "### Table Customer\n",
    "source:  customer table\n",
    "\n",
    "| Source Field | Target Field | Transformation Rule     |\n",
    "|--------------|--------------|-------------------------|\n",
    "| -            | customer_id  | Auto Generated          |\n",
    "| customer_id  | customer_nk  | Direct Mapping, unique  |\n",
    "| first_name   | first_name   | Direct Mapping          |\n",
    "| last_name    | last_name    | Direct Mapping          |\n",
    "| email        | email        | Direct Mapping, unique          |\n",
    "| phone        | phone        | Direct Mapping          |\n",
    "| address      | address      | Direct Mapping          |\n",
    "\n",
    "\n",
    "\n",
    "## Table orders\n",
    "source: orders table\n",
    "\n",
    "| Source Field | Target Field | Transformation Rule                                   |\n",
    "|--------------|--------------|-------------------------------------------------------|\n",
    "| -            | order_id     | Auto Generated                                        |\n",
    "| order_id     | order_nk     | Direct Mapping                                        |\n",
    "| customer_id  | customer_id  | Use the customer_nk from the customer table by matching the customer_id (source) |\n",
    "| order_date   | order_date   | Direct Mapping                                        |\n",
    "| status       | status       | Direct Mapping                                        |\n",
    "\n",
    "Do Deduplication to get unique order data by order_id\n",
    "\n",
    "## Table order_detail\n",
    "source: orders table\n",
    "\n",
    "| Source Field | Target Field     | Transformation Rule                                                |\n",
    "|--------------|------------------|--------------------------------------------------------------------|\n",
    "| -            | order_detail_id  | Auto Generated                                                     |\n",
    "| order_id     | order_id         | Use the order_nk from the orders table by matching the order_id (source)    |\n",
    "| product_id   | product_id       | Direct Mapping                                                     |\n",
    "| price        | price            | Direct Mapping                                                     |\n",
    "| quantity     | quantity         | Direct Mapping                                                     |\n",
    "\n",
    "Do Deduplication to get unique order data by order_id, product_id and quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some validation rules that can be applied to the previously mentioned tables to ensure data integrity and quality:\n",
    "\n",
    "### Validation Rule\n",
    "1. Customer Table Validation:\n",
    "    - Check first_name and last_name are not null or empty.\n",
    "    - Validate email for correct format (yahoo.com, hotmail.com, gmail.com)\n",
    "\n",
    "2. Order Detail Table Validation:\n",
    "    - Validate price to ensure it is a positive number.\n",
    "    - Validate quantity to ensure it is a positive integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "#The Minio libray is used to interact with a MinIO server. \n",
    "from minio import Minio\n",
    "\n",
    "# BytesIO provides a way to work with binary data in memory as if it were a file.\n",
    "from io import BytesIO\n",
    "\n",
    "from src.log.log import log_to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract From Staging Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_staging(table_name: str): \n",
    "    \n",
    "    try:\n",
    "        # create connection to database staging\n",
    "        conn = create_engine(\"postgresql://postgres:aku@localhost/staging\")\n",
    "\n",
    "        log = pd.read_csv(\"log.csv\")\n",
    "\n",
    "        # Get date from previous process\n",
    "        condition = (\n",
    "            (log['step'] == 'extraction') &\n",
    "            (log['status'] == 'success') &\n",
    "            (log['source'] == 'staging') &\n",
    "            (log['table_name'] == table_name)\n",
    "        )\n",
    "\n",
    "        # Apply the filter\n",
    "        etl_date = log[condition]['etl_date']\n",
    "\n",
    "        # If no previous extraction has been recorded (etl_date is empty), set etl_date to '1111-01-01' indicating the initial load.\n",
    "        # Otherwise, retrieve data added since the last successful extraction (etl_date).\n",
    "        if(etl_date.empty):\n",
    "            etl_date = '1111-01-01'\n",
    "        else:\n",
    "            etl_date = max(etl_date)\n",
    "\n",
    "        # Constructs a SQL query to select all columns from the specified table_name where created_at is greater than etl_date.\n",
    "        query = f\"SELECT * FROM {table_name} WHERE created_at > %s::timestamp\"\n",
    "\n",
    "        # Execute the query with pd.read_sql\n",
    "        df = pd.read_sql(sql=query, con=conn, params=(etl_date,))\n",
    "        log_msg = {\n",
    "                \"step\" : \"extraction\",\n",
    "                \"status\": \"success\",\n",
    "                \"source\": \"staging\",\n",
    "                \"table_name\": table_name,\n",
    "                \"etl_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Current timestamp\n",
    "            }\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log_msg = {\n",
    "            \"step\" : \"extraction\",\n",
    "            \"status\": \"failed\",\n",
    "            \"source\": \"staging\",\n",
    "            \"table_name\": table_name,\n",
    "            \"etl_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Current timestamp\n",
    "        }\n",
    "        print(e)\n",
    "    finally:\n",
    "        log_to_csv(log_msg, 'log.csv')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each table has different behavior, each target table has its own transformation and validation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_category(data: pd.DataFrame):\n",
    "\n",
    "    try:\n",
    "        # rename column category to category_nk\n",
    "        data = data.rename(columns={'category_id':'category_nk'})\n",
    "\n",
    "        # deduplication based on category_nk and category name\n",
    "        data = data.drop_duplicates(subset='category_nk')\n",
    "        data = data.drop_duplicates(subset='name')\n",
    "        \n",
    "        log_msg = {\n",
    "                \"step\" : \"transformation\",\n",
    "                \"status\": \"success\",\n",
    "                \"source\": \"staging\",\n",
    "                \"table_name\": \"category\",\n",
    "                \"etl_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Current timestamp\n",
    "                }\n",
    "        \n",
    "        return data\n",
    "    except Exception as e:\n",
    "        log_msg = {\n",
    "            \"step\" : \"transformation\",\n",
    "            \"status\": \"failed\",\n",
    "            \"source\": \"staging\",\n",
    "            \"table_name\": \"category\",\n",
    "            \"etl_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Current timestamp\n",
    "            }\n",
    "    finally:\n",
    "        log_to_csv(log_msg, 'log.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutomer Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_customer(data: pd.DataFrame):\n",
    "    try:\n",
    "        # rename column customer to customer_nk\n",
    "        data = data.rename(columns={'customer_id':'customer_nk'})\n",
    "\n",
    "        #deduplication based on customer_nk and email\n",
    "        data = data.drop_duplicates(subset='customer_nk')\n",
    "        data = data.drop_duplicates(subset='email')\n",
    "                \n",
    "        log_msg = {\n",
    "                \"step\" : \"transformation\",\n",
    "                \"status\": \"success\",\n",
    "                \"source\": \"staging\",\n",
    "                \"table_name\": \"customer\",\n",
    "                \"etl_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Current timestamp\n",
    "                }\n",
    "        \n",
    "        return data\n",
    "    except Exception as e:\n",
    "        log_msg = {\n",
    "            \"step\" : \"transformation\",\n",
    "            \"status\": \"failed\",\n",
    "            \"source\": \"staging\",\n",
    "            \"table_name\": \"customer\",\n",
    "            \"etl_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Current timestamp\n",
    "            }\n",
    "    finally:\n",
    "        log_to_csv(log_msg, 'log.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order table has a relationship with the customer table, so it is necessary to obtain the customer_id from our target database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_target(table_name: str):\n",
    "    \"\"\"\n",
    "    Fungsi untuk mengekstrak data dari database target\n",
    "    \"\"\"\n",
    "    conn = create_engine(\"postgresql://postgres:aku@localhost/wh_w4\")\n",
    "\n",
    "    # Constructs a SQL query to select all columns from the specified table_name where created_at is greater than etl_date.\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "\n",
    "    # Execute the query with pd.read_sql\n",
    "    df = pd.read_sql(sql=query, con=conn)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_orders(data: pd.DataFrame):\n",
    "    try:\n",
    "        # rename column order_id and customer_id\n",
    "        rename_column = {\n",
    "            'order_id':'order_nk',\n",
    "            'customer_id':'customer_nk'\n",
    "        }\n",
    "        # select column\n",
    "        selected_column = ['order_nk', 'customer_id', 'order_date', 'status']\n",
    "\n",
    "        #extract data customer from target\n",
    "        data_cust = extract_target(table_name='customer')\n",
    "        \n",
    "        data = data.rename(columns=rename_column)\n",
    "\n",
    "        #deduplication based on ['order_nk','customer_nk','order_date','status'] (profiling result)\n",
    "        data = data.drop_duplicates(subset=['order_nk','customer_nk','order_date','status'])\n",
    "\n",
    "        # get customer_id from tabel customer in database target\n",
    "        merged_data = data.merge(data_cust[['customer_id', 'customer_nk']], left_on='customer_nk', right_on='customer_nk', how='left')\n",
    "\n",
    "        log_msg = {\n",
    "                \"step\" : \"transformation\",\n",
    "                \"status\": \"success\",\n",
    "                \"source\": \"staging\",\n",
    "                \"table_name\": \"orders\",\n",
    "                \"etl_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Current timestamp\n",
    "                }\n",
    "        \n",
    "        return merged_data[selected_column]\n",
    "    except Exception as e:\n",
    "        log_msg = {\n",
    "            \"step\" : \"transformation\",\n",
    "            \"status\": \"failed\",\n",
    "            \"source\": \"staging\",\n",
    "            \"table_name\": \"orders\",\n",
    "            \"etl_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Current timestamp\n",
    "            }\n",
    "        print(e)\n",
    "    finally:\n",
    "        log_to_csv(log_msg, 'log.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Order Detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order_detail table has a relationship with the orders table, so it is necessary to obtain the order_id from our target database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_order_detail(data: pd.DataFrame):\n",
    "    try:\n",
    "        #rename column order_nk\n",
    "        rename_column = {\n",
    "            'order_id':'order_nk',\n",
    "        }\n",
    "\n",
    "        #select column\n",
    "        selected_column = ['order_id', 'product_id', 'price', 'quantity']\n",
    "\n",
    "        #extarct table orders from database target\n",
    "        data_orders = extract_target(table_name='orders')\n",
    "        \n",
    "        data = data.rename(columns=rename_column)\n",
    "\n",
    "        #deduplication based on ['order_nk','product_id','quantity']\n",
    "        data = data.drop_duplicates(subset=['order_nk','product_id','quantity'])\n",
    "\n",
    "        # get order_id from table orders in database target\n",
    "        merged_data = data.merge(data_orders[['order_id', 'order_nk']], left_on='order_nk', right_on='order_nk', how='left')\n",
    "\n",
    "                \n",
    "        log_msg = {\n",
    "                \"step\" : \"transformation\",\n",
    "                \"status\": \"success\",\n",
    "                \"source\": \"staging\",\n",
    "                \"table_name\": \"order_detail\",\n",
    "                \"etl_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Current timestamp\n",
    "                }\n",
    "        \n",
    "        return merged_data[selected_column]\n",
    "    except Exception as e:\n",
    "        log_msg = {\n",
    "            \"step\" : \"transformation\",\n",
    "            \"status\": \"failed\",\n",
    "            \"source\": \"staging\",\n",
    "            \"table_name\": \"order_detail\",\n",
    "            \"etl_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Current timestamp\n",
    "            }\n",
    "        print(e)\n",
    "    finally:\n",
    "        log_to_csv(log_msg, 'log.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation not null column\n",
    "def validate_not_empty(value):\n",
    "    return bool(value and value.strip())\n",
    "\n",
    "#validation email domain\n",
    "def validate_email_format(email):\n",
    "    email_regex = re.compile(r\"^[\\w\\.-]+@(yahoo\\.com|hotmail\\.com|gmail\\.com)$\")\n",
    "    return bool(email_regex.match(email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvaldiation_customer\u001b[39m(data: \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame, table_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m         \u001b[38;5;66;03m# Create a report DataFrame\u001b[39;00m\n\u001b[0;32m      5\u001b[0m         report_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_name_valid\u001b[39m\u001b[38;5;124m'\u001b[39m: data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(validate_not_empty),\n\u001b[0;32m      7\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_name_valid\u001b[39m\u001b[38;5;124m'\u001b[39m: data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(validate_not_empty),\n\u001b[0;32m      8\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124memail_format_valid\u001b[39m\u001b[38;5;124m'\u001b[39m: data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memail\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(validate_email_format),\n\u001b[0;32m      9\u001b[0m         }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def valdiation_customer(data: pd.DataFrame, table_name: str):\n",
    "    try:\n",
    "\n",
    "        # Create a report DataFrame\n",
    "        report_data = {\n",
    "            'first_name_valid': data['first_name'].apply(validate_not_empty),\n",
    "            'last_name_valid': data['last_name'].apply(validate_not_empty),\n",
    "            'email_format_valid': data['email'].apply(validate_email_format),\n",
    "        }\n",
    "\n",
    "        report_df = pd.DataFrame(report_data)\n",
    "\n",
    "        # summirize status data by all condition\n",
    "        report_df['all_valid'] = report_df.all(axis=1)\n",
    "\n",
    "        # Filter out valid rows (all_valid = 'True')\n",
    "        valid_customers_df = data[report_df['all_valid']]\n",
    "\n",
    "        # Filter out invalid rows (all_valid = 'False')\n",
    "        invalid_customers_df = data[~report_df['all_valid']]\n",
    "        \n",
    "        #create success log message\n",
    "        log_msg = {\n",
    "                \"step\" : \"validation\",\n",
    "                \"status\": \"success\",\n",
    "                \"source\": 'staging',\n",
    "                \"table_name\": table_name,\n",
    "                \"etl_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Current timestamp\n",
    "            }\n",
    "        return valid_customers_df, invalid_customers_df\n",
    "    except Exception as e:\n",
    "        #create fail log message\n",
    "        log_msg = {\n",
    "            \"step\" : \"validation\",\n",
    "            \"status\": \"failed\",\n",
    "            \"source\": \"staging\",\n",
    "            \"table_name\": table_name,\n",
    "            \"etl_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Current timestamp\n",
    "        }\n",
    "    finally:\n",
    "        log_to_csv(log_msg, 'log.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order Detail Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_positive_number(value):\n",
    "    return pd.notna(value) and value > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valdiation_order_detail(data: pd.DataFrame, table_name: str):\n",
    "    try:\n",
    "        # Create a report DataFrame\n",
    "        report_data = {\n",
    "            'price_valid': data['price'].apply(validate_positive_number),\n",
    "            'quantity_valid': data['quantity'].apply(validate_positive_number)\n",
    "        }\n",
    "\n",
    "        report_df = pd.DataFrame(report_data)\n",
    "        \n",
    "        # summirize status data by all condition\n",
    "        report_df['all_valid'] = report_df.all(axis=1)\n",
    "\n",
    "        # Filter out valid rows (all_valid = 'True')\n",
    "        valid_order_details_df = data[report_df['all_valid']]\n",
    "\n",
    "        # Filter out invalid rows (all_valid = 'False')\n",
    "        invalid_order_details_df = data[~report_df['all_valid']]\n",
    "        \n",
    "        #create success log message\n",
    "        log_msg = {\n",
    "                \"step\" : \"validation\",\n",
    "                \"status\": \"success\",\n",
    "                \"source\": 'staging',\n",
    "                \"table_name\": table_name,\n",
    "                \"etl_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Current timestamp\n",
    "            }\n",
    "        return valid_order_details_df, invalid_order_details_df\n",
    "    except Exception as e:\n",
    "        #create fail log message\n",
    "        log_msg = {\n",
    "            \"step\" : \"validation\",\n",
    "            \"status\": \"failed\",\n",
    "            \"source\": \"staging\",\n",
    "            \"table_name\": table_name,\n",
    "            \"etl_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Current timestamp\n",
    "        }\n",
    "    finally:\n",
    "        log_to_csv(log_msg, 'log.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangres import upsert\n",
    "from src.load.load_error import handle_error\n",
    "def load_target(data:pd.DataFrame, schema:str, table_name: str, idx_name:str, source):\n",
    "    try:\n",
    "        # create connection to database\n",
    "        conn = create_engine(\"postgresql://postgres:aku@localhost/wh_w4\")\n",
    "        \n",
    "        # set data index or primary key\n",
    "        data = data.set_index(idx_name)\n",
    "        \n",
    "        # Do upsert (Update for existing data and Insert for new data)\n",
    "        upsert(con = conn,\n",
    "                df = data,\n",
    "                table_name = table_name,\n",
    "                schema = schema,\n",
    "                if_row_exists = \"update\")\n",
    "        \n",
    "        #create success log message\n",
    "        log_msg = {\n",
    "                \"step\" : \"load target\",\n",
    "                \"status\": \"success\",\n",
    "                \"source\": source,\n",
    "                \"table_name\": table_name,\n",
    "                \"etl_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Current timestamp\n",
    "            }\n",
    "        return data\n",
    "    except Exception as e:\n",
    "\n",
    "        #create fail log message\n",
    "        log_msg = {\n",
    "            \"step\" : \"load target\",\n",
    "            \"status\": \"failed\",\n",
    "            \"source\": source,\n",
    "            \"table_name\": table_name,\n",
    "            \"etl_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Current timestamp\n",
    "        }\n",
    "        print(e)\n",
    "        # Handling error: save data to Object Storage\n",
    "        try:\n",
    "            handle_error(data = data, bucket_name='error', table_name= table_name)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    finally:\n",
    "        log_to_csv(log_msg, 'log.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Staging to Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_nk</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computers&amp;Accessories</td>\n",
       "      <td>Computers&amp;Accessories is Skill final here skin...</td>\n",
       "      <td>2024-07-02 15:06:39.594703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Electronics is Letter offer probably state org...</td>\n",
       "      <td>2024-07-02 15:06:39.594703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MusicalInstruments</td>\n",
       "      <td>MusicalInstruments is Above without but federa...</td>\n",
       "      <td>2024-07-02 15:06:39.594703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OfficeProducts</td>\n",
       "      <td>OfficeProducts is Letter participant lot indic...</td>\n",
       "      <td>2024-07-02 15:06:39.594703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HomeImprovement</td>\n",
       "      <td>HomeImprovement is Meeting senior student win ...</td>\n",
       "      <td>2024-07-02 15:06:39.594703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Toys&amp;Games</td>\n",
       "      <td>Toys&amp;Games is Local summer prevent authority h...</td>\n",
       "      <td>2024-07-02 15:06:39.594703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Car&amp;Motorbike</td>\n",
       "      <td>Car&amp;Motorbike is Big people role me play onto.</td>\n",
       "      <td>2024-07-02 15:06:39.594703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Health&amp;PersonalCare</td>\n",
       "      <td>Health&amp;PersonalCare is Stand response prove co...</td>\n",
       "      <td>2024-07-02 15:06:39.594703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>Home&amp;Kitchen is Service discussion again sea a...</td>\n",
       "      <td>2024-07-02 15:06:39.594703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name  \\\n",
       "category_nk                          \n",
       "1            Computers&Accessories   \n",
       "2                      Electronics   \n",
       "3               MusicalInstruments   \n",
       "4                   OfficeProducts   \n",
       "6                  HomeImprovement   \n",
       "7                       Toys&Games   \n",
       "8                    Car&Motorbike   \n",
       "9              Health&PersonalCare   \n",
       "5                 Home and Kitchen   \n",
       "\n",
       "                                                   description  \\\n",
       "category_nk                                                      \n",
       "1            Computers&Accessories is Skill final here skin...   \n",
       "2            Electronics is Letter offer probably state org...   \n",
       "3            MusicalInstruments is Above without but federa...   \n",
       "4            OfficeProducts is Letter participant lot indic...   \n",
       "6            HomeImprovement is Meeting senior student win ...   \n",
       "7            Toys&Games is Local summer prevent authority h...   \n",
       "8               Car&Motorbike is Big people role me play onto.   \n",
       "9            Health&PersonalCare is Stand response prove co...   \n",
       "5            Home&Kitchen is Service discussion again sea a...   \n",
       "\n",
       "                            created_at  \n",
       "category_nk                             \n",
       "1           2024-07-02 15:06:39.594703  \n",
       "2           2024-07-02 15:06:39.594703  \n",
       "3           2024-07-02 15:06:39.594703  \n",
       "4           2024-07-02 15:06:39.594703  \n",
       "6           2024-07-02 15:06:39.594703  \n",
       "7           2024-07-02 15:06:39.594703  \n",
       "8           2024-07-02 15:06:39.594703  \n",
       "9           2024-07-02 15:06:39.594703  \n",
       "5           2024-07-02 15:06:39.594703  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Transform and Load Category\n",
    "df_category = extract_staging(table_name='category')\n",
    "category_transform = transform_category(data=df_category)\n",
    "load_target(data=category_transform,\n",
    "            schema=\"public\",\n",
    "            table_name='category',\n",
    "            idx_name='category_nk',\n",
    "            source='staging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>address</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_nk</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jackie</td>\n",
       "      <td>Butler</td>\n",
       "      <td>jackie740@hotmail.com</td>\n",
       "      <td>639-601-6489</td>\n",
       "      <td>0682 Davis Mount\\nNorth Ryan, DE 34214</td>\n",
       "      <td>2024-07-02 15:50:53.961925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ryan</td>\n",
       "      <td>Brown</td>\n",
       "      <td>ryan611@gmail.com</td>\n",
       "      <td>7246609373</td>\n",
       "      <td>087 Michael Mountain\\nPort Dominiquechester, V...</td>\n",
       "      <td>2024-07-02 15:50:53.961925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>Allen</td>\n",
       "      <td>virginia858@yahoo.com</td>\n",
       "      <td>+1-938-242-0900</td>\n",
       "      <td>845 Amanda Turnpike\\nChadbury, AS 71148</td>\n",
       "      <td>2024-07-02 15:50:53.961925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patty</td>\n",
       "      <td>Allen</td>\n",
       "      <td>patty464@hotmail.com</td>\n",
       "      <td>431.665.1039x74107</td>\n",
       "      <td>48782 Lisa Centers Suite 303\\nEast Marieton, V...</td>\n",
       "      <td>2024-07-02 15:50:53.961925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bryan</td>\n",
       "      <td>Gonzalez</td>\n",
       "      <td>bryan273@yahoo.com</td>\n",
       "      <td>268.200.7349x794</td>\n",
       "      <td>5896 Caitlin Radial Suite 467\\nPort Maryfurt, ...</td>\n",
       "      <td>2024-07-02 15:50:53.961925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>Reginald</td>\n",
       "      <td>Becker</td>\n",
       "      <td>reginald548@hotmail.com</td>\n",
       "      <td>595-251-4621x510</td>\n",
       "      <td>589 Monica Landing Apt. 451\\nLake James, NH 61198</td>\n",
       "      <td>2024-07-02 15:50:53.961925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>Phyllis</td>\n",
       "      <td>Lewis</td>\n",
       "      <td>phyllis553@yahoo.com</td>\n",
       "      <td>001-294-785-8996x82361</td>\n",
       "      <td>794 Wallace Circle\\nHernandeztown, WV 14386</td>\n",
       "      <td>2024-07-02 15:50:53.961925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>Christopher</td>\n",
       "      <td>Smith</td>\n",
       "      <td>christopher077@hotmail.com</td>\n",
       "      <td>001-282-853-7711x0234</td>\n",
       "      <td>33341 Chen Gateway\\nHaileyborough, AK 69666</td>\n",
       "      <td>2024-07-02 15:50:53.961925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>Kenneth</td>\n",
       "      <td>Berry</td>\n",
       "      <td>kenneth878@yahoo.com</td>\n",
       "      <td>(430)513-6409x6624</td>\n",
       "      <td>9067 Gray Hills Apt. 024\\nKevinview, NY 11486</td>\n",
       "      <td>2024-07-02 15:50:53.961925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>Jimmy</td>\n",
       "      <td>Mora</td>\n",
       "      <td>jimmy106@yahoo.com</td>\n",
       "      <td>(237)284-1659x115</td>\n",
       "      <td>222 Scott Trail\\nDonnamouth, MN 80492</td>\n",
       "      <td>2024-07-02 15:50:53.961925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              first_name last_name                       email  \\\n",
       "customer_nk                                                      \n",
       "1                 Jackie    Butler       jackie740@hotmail.com   \n",
       "2                   Ryan     Brown           ryan611@gmail.com   \n",
       "3               Virginia     Allen       virginia858@yahoo.com   \n",
       "4                  Patty     Allen        patty464@hotmail.com   \n",
       "5                  Bryan  Gonzalez          bryan273@yahoo.com   \n",
       "...                  ...       ...                         ...   \n",
       "978             Reginald    Becker     reginald548@hotmail.com   \n",
       "979              Phyllis     Lewis        phyllis553@yahoo.com   \n",
       "980          Christopher     Smith  christopher077@hotmail.com   \n",
       "981              Kenneth     Berry        kenneth878@yahoo.com   \n",
       "982                Jimmy      Mora          jimmy106@yahoo.com   \n",
       "\n",
       "                              phone  \\\n",
       "customer_nk                           \n",
       "1                      639-601-6489   \n",
       "2                        7246609373   \n",
       "3                   +1-938-242-0900   \n",
       "4                431.665.1039x74107   \n",
       "5                  268.200.7349x794   \n",
       "...                             ...   \n",
       "978                595-251-4621x510   \n",
       "979          001-294-785-8996x82361   \n",
       "980           001-282-853-7711x0234   \n",
       "981              (430)513-6409x6624   \n",
       "982               (237)284-1659x115   \n",
       "\n",
       "                                                       address  \\\n",
       "customer_nk                                                      \n",
       "1                       0682 Davis Mount\\nNorth Ryan, DE 34214   \n",
       "2            087 Michael Mountain\\nPort Dominiquechester, V...   \n",
       "3                      845 Amanda Turnpike\\nChadbury, AS 71148   \n",
       "4            48782 Lisa Centers Suite 303\\nEast Marieton, V...   \n",
       "5            5896 Caitlin Radial Suite 467\\nPort Maryfurt, ...   \n",
       "...                                                        ...   \n",
       "978          589 Monica Landing Apt. 451\\nLake James, NH 61198   \n",
       "979                794 Wallace Circle\\nHernandeztown, WV 14386   \n",
       "980                33341 Chen Gateway\\nHaileyborough, AK 69666   \n",
       "981              9067 Gray Hills Apt. 024\\nKevinview, NY 11486   \n",
       "982                      222 Scott Trail\\nDonnamouth, MN 80492   \n",
       "\n",
       "                            created_at  \n",
       "customer_nk                             \n",
       "1           2024-07-02 15:50:53.961925  \n",
       "2           2024-07-02 15:50:53.961925  \n",
       "3           2024-07-02 15:50:53.961925  \n",
       "4           2024-07-02 15:50:53.961925  \n",
       "5           2024-07-02 15:50:53.961925  \n",
       "...                                ...  \n",
       "978         2024-07-02 15:50:53.961925  \n",
       "979         2024-07-02 15:50:53.961925  \n",
       "980         2024-07-02 15:50:53.961925  \n",
       "981         2024-07-02 15:50:53.961925  \n",
       "982         2024-07-02 15:50:53.961925  \n",
       "\n",
       "[997 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Transform and Load Customer\n",
    "df_customer = extract_staging(table_name='customer')\n",
    "customer_transform = transform_customer(data=df_customer)\n",
    "valid_customer, invalid_customer = valdiation_customer(data = customer_transform,\n",
    "                                     table_name='customer')\n",
    "load_target(data=valid_customer,\n",
    "            schema=\"public\",\n",
    "            table_name='customer',\n",
    "            idx_name='customer_nk',\n",
    "            source='staging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_nk</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IINI91PP812</th>\n",
       "      <td>2691.0</td>\n",
       "      <td>2022-01-30</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONNA03MN757</th>\n",
       "      <td>2167.0</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPCC44AC852</th>\n",
       "      <td>2834.0</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMIM69AM147</th>\n",
       "      <td>2957.0</td>\n",
       "      <td>2021-06-26</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCIA31MO690</th>\n",
       "      <td>2331.0</td>\n",
       "      <td>2021-07-09</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COOC58NA784</th>\n",
       "      <td>2146.0</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMNA61OM567</th>\n",
       "      <td>1996.0</td>\n",
       "      <td>2021-02-06</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AANA44AN436</th>\n",
       "      <td>2633.0</td>\n",
       "      <td>2021-04-24</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IAAC58MO380</th>\n",
       "      <td>2524.0</td>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANAC00PM416</th>\n",
       "      <td>2701.0</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>870 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             customer_id  order_date   status\n",
       "order_nk                                     \n",
       "IINI91PP812       2691.0  2022-01-30  Success\n",
       "ONNA03MN757       2167.0  2021-01-03  Success\n",
       "NPCC44AC852       2834.0  2022-09-08  Success\n",
       "MMIM69AM147       2957.0  2021-06-26  Success\n",
       "MCIA31MO690       2331.0  2021-07-09  Success\n",
       "...                  ...         ...      ...\n",
       "COOC58NA784       2146.0  2022-09-27  Success\n",
       "NMNA61OM567       1996.0  2021-02-06  Success\n",
       "AANA44AN436       2633.0  2021-04-24  Success\n",
       "IAAC58MO380       2524.0  2022-10-10  Success\n",
       "ANAC00PM416       2701.0  2022-12-31  Success\n",
       "\n",
       "[870 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Transform and Load orders\n",
    "df_orders = extract_staging(table_name='orders')\n",
    "orders_transform = transform_orders(data=df_orders)\n",
    "load_target(data=orders_transform,\n",
    "            schema=\"public\",\n",
    "            table_name='orders',\n",
    "            idx_name='order_nk',\n",
    "            source='staging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">871</th>\n",
       "      <th>B08ZN4B121</th>\n",
       "      <th>7</th>\n",
       "      <td>1599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0B94JPY2N</th>\n",
       "      <th>13</th>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B07MP21WJD</th>\n",
       "      <th>9</th>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B08G43CCLC</th>\n",
       "      <th>9</th>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <th>B0B217Z5VK</th>\n",
       "      <th>5</th>\n",
       "      <td>3999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <th>B07NKNBTT3</th>\n",
       "      <th>1</th>\n",
       "      <td>1230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1739</th>\n",
       "      <th>B0083T231O</th>\n",
       "      <th>15</th>\n",
       "      <td>1499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B07VZYMQNZ</th>\n",
       "      <th>4</th>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B09PTT8DZF</th>\n",
       "      <th>10</th>\n",
       "      <td>670.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <th>B07JF9B592</th>\n",
       "      <th>15</th>\n",
       "      <td>699.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3629 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               price\n",
       "order_id product_id quantity        \n",
       "871      B08ZN4B121 7         1599.0\n",
       "         B0B94JPY2N 13         999.0\n",
       "         B07MP21WJD 9          299.0\n",
       "         B08G43CCLC 9          999.0\n",
       "872      B0B217Z5VK 5         3999.0\n",
       "...                              ...\n",
       "1738     B07NKNBTT3 1         1230.0\n",
       "1739     B0083T231O 15        1499.0\n",
       "         B07VZYMQNZ 4         1440.0\n",
       "         B09PTT8DZF 10         670.0\n",
       "1740     B07JF9B592 15         699.0\n",
       "\n",
       "[3629 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform and Load order_detail\n",
    "order_detail_transform = transform_order_detail(data=df_orders)\n",
    "valid_order_detail, invalid_order_detail = valdiation_order_detail(data = order_detail_transform,\n",
    "                                     table_name='customer')\n",
    "load_target(data=valid_order_detail,\n",
    "            schema=\"public\",\n",
    "            table_name='order_detail',\n",
    "            idx_name=['order_id', 'product_id', 'quantity'],\n",
    "            source='staging')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link git repository: https://github.com/Kurikulum-Sekolah-Pacmann/ingestion_data_pipeline.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
